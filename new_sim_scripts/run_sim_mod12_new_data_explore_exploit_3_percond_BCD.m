
for ID = 501:560
    
    disp(ID)
    
    n_trials = 4000;
    
    pi_SH = nan(n_trials/2,4);
    pi_exploit_SH = nan(n_trials/2,1);
    pi_explore_SH = nan(n_trials/2,1);
    pi_novel_SH = nan(n_trials/2,1);
    pi_bad_SH = nan(n_trials/2,1);

    pi_LH = nan(n_trials/2,4);
    pi_exploit_LH = nan(n_trials/2,1);
    pi_explore_LH = nan(n_trials/2,1);
    pi_novel_LH = nan(n_trials/2,1);
    pi_bad_LH = nan(n_trials/2,1);

    %% load parameter values
    params_dir = 'D:\MaggiesFarm\modeling_28_02\participant_data\thompson_noveltybonus_2nov_MAP\3params_2Hor_Q01_2sgm0\results\';
    tmp_res=load(strcat(params_dir,'res_thompson_',num2str(ID),'_results.mat'));
    para_vals = tmp_res.mEparams;
       
    %% settings
    settings = [];
    settings.task.N_hor = 2;
    settings.task.N_trees = 3; % Changed
    settings.opts.TLT       = [];
    settings.funs.decfun        = @softmax;
    settings.funs.valuefun      = @mvnorm_Thompson_noveltybonus_new; %@hybrid; % @thompson; % 
    settings.funs.priorfun      = [];
    settings.funs.learningfun   = @kalman_filt;
    settings.desc = ['sim_thompson_noveltybonus' int2str(ID)];    % description of model (settings, etc)
    settings.params.param_names = {'sgm0', '', 'Q0','xi', '', 'eta', ''};   % is same param name as prev, write ''
    params.task.exp.n_blocks            = 4;    
    params.task.exp.n_trialPB           = n_trials/params.task.exp.n_blocks ;%1000   % trials per block
    settings.task.N_games = params.task.exp.n_blocks*params.task.exp.n_trialPB;
    settings.task.Ngames_per_hor = settings.task.N_games / settings.task.N_hor;
    n_trials = settings.task.N_games;
    
    %% initialise model
    mo = initialise_model_MF_S0fixed_eta_new(settings);

    %% fill in parameters, model-funs etc
    mo = prep_model_MF(mo,settings,para_vals,settings.params.param_names);

        % Generate apple sequences
        [user, params] = apple_params_for_sim(ID,params); 
         
        u_tmp = unique([user.block(1).item(:,2); user.block(2).item(:,2); user.block(3).item(:,2); user.block(4).item(:,2)]);
        if size(u_tmp,1)~=params.task.exp.n_trialPB % TODO: find problem in present_applesSIM2!!
            disp('Should be 100 !!')
            disp(size(u_tmp,1))
        end

        [user, params] = present_applesSIM_3(params, user); % on lui renvoie le user dedans a chaque fois ? pourquoi pas boucle dedans?
        
        [data,gameIDs] = aggregateDataSIM(params, user);       
          
    
    %% loop through trials (and conditions) to generate behaviour
    for c = 1:settings.task.N_hor
        for g = 1:settings.task.Ngames_per_hor       
            
            data(c,g).gameID = gameIDs(c,g);
        
            % data
            tmp_dat = data(c,g);

            if tmp_dat.unshown_tree == 1
                
                tmp_dat = rmfield(tmp_dat,'a');   

                % loop through trials of game
                for t = 1:size(tmp_dat.alltrees,1)+1 %CHANGED

                mo.mat.appleA{c,g} = data(c,g).a;
                mo.mat.appleB{c,g} = data(c,g).b;
                mo.mat.appleD{c,g} = data(c,g).d;

                exploitTree(g,c)=2;

                    if t == 1 % plug in priors
                        mo.mat.Q{c,g}(:,t) = mo.params.Q0(1); 
                        mo.mat.sgm{c,g}(:,t) = mo.params.sgm0(c);
                    end

                    % see outcome and learn
                    if t <= size(tmp_dat.alltrees,1) %CHANGED
                        mo = mo.funs.learningfun(mo,tmp_dat,c,g,t);
                    else
                        % calculate values & policy
                        mo = mo.funs.valuefun(mo,c,g,t);

                            % add lapse if needed
                            if ~isempty(mo.params.xi) %epsilon greedy
                                mo = lapse(mo,c,g,t);
                            end
                    end
                end

                tmp_pi = nanmean(mo.mat.pi{c,g},2);
                
               %  policy
                if c == 1

                    tmp_pi_SH = nanmean(mo.mat.pi{c,g},2)'; 

                    pi_SH(g,:) = [nan tmp_pi_SH(1:3)];
                    
                    pi_exploit_SH(g,1) = tmp_pi_SH(1);
                    pi_explore_SH(g,1) = nan;
                    pi_novel_SH(g,1) = tmp_pi_SH(2);
                    pi_bad_SH(g,1) = tmp_pi_SH(3);

                elseif c==2 

                    tmp_pi_LH = nanmean(mo.mat.pi{c,g},2)'; 

                    pi_LH(g,:) = [nan tmp_pi_LH(1:3)];
                    pi_exploit_LH(g,1) = tmp_pi_LH(1);
                    pi_explore_LH(g,1) = nan;
                    pi_novel_LH(g,1) = tmp_pi_LH(2);
                    pi_bad_LH(g,1) = tmp_pi_LH(3);

                end

                % make choice based on policy
                r = rand(1);    % random choice seed
                tmp_cPi = cumsum(tmp_pi);
                tmp_chosen = find(tmp_cPi>=r,1,'first');


                tree_vec = [2, 3, 4];

                data(c,g).chosen = tree_vec(tmp_chosen); % Changed    
            end
            
        end
    end
    
    pi_SH_average(ID-500,:) = nansum(pi_SH,1)/(n_trials/2);
    pi_LH_average(ID-500,:) = nansum(pi_LH,1)/(n_trials/2);
    
    pi_SH_Exploit = [pi_exploit_SH, pi_explore_SH, pi_novel_SH, pi_bad_SH];
    pi_LH_Exploit = [pi_exploit_LH, pi_explore_LH, pi_novel_LH, pi_bad_LH];
    
    pi_SH_average_Exploit(ID-500,:) = nansum(pi_SH_Exploit,1)/(n_trials/2);
    pi_LH_average_Exploit(ID-500,:) = nansum(pi_LH_Exploit,1)/(n_trials/2);
    
    
    sim_data_dir = strcat('D:\MaggiesFarm\modeling_28_02\simulation_data\simulated_data_from_fitted_params_mod12_BCD\num_trials_',int2str(n_trials),'\participant_',int2str(ID),'\');
    if ~exist(sim_data_dir)
        mkdir(sim_data_dir)
    end
    save(strcat(sim_data_dir,'\data.mat'), 'data')

end

sim_prob_choosing_trees_new_data_desc = {'A_SH', 'B_SH', 'C_SH', 'D_SH', 'A_LH', 'B_LH', 'C_LH', 'D_LH'};
sim_prob_choosing_trees_new_data = [pi_SH_average, pi_LH_average];

sim_prob_choosing_exploit_trees_new_data_desc = {'Exploit_SH', 'Explore_SH', 'C_SH', 'D_SH', 'Exploit_LH', 'Explore_LH', 'C_LH', 'D_LH'};
sim_prob_choosing_exploit_trees_new_data = [pi_SH_average_Exploit, pi_LH_average_Exploit];

save('D:\writing\MF\data_for_figs\sim_prob_choosing_trees_new_data_BCD.mat', 'sim_prob_choosing_trees_new_data');
save('D:\writing\MF\data_for_figs\sim_prob_choosing_trees_new_data_desc.mat', 'sim_prob_choosing_trees_new_data_desc');

save('D:\writing\MF\data_for_figs\sim_prob_choosing_exploit_trees_new_data_BCD.mat', 'sim_prob_choosing_exploit_trees_new_data');
save('D:\writing\MF\data_for_figs\sim_prob_choosing_exploit_trees_new_data_desc.mat', 'sim_prob_choosing_exploit_trees_new_data_desc');

